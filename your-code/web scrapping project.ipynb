{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTE TRABAJO BUSCA LOCALIZAR LA REGIÓN CON MÁS PREMIOS GASTRONÓMICOS Y REFUTAR LA HIPÓTESIS DE QUE EL RANKING ES EUROCENTRISTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theworlds50best.com/list/1-50-winners'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer sopa\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinar rankings\n",
    "ranking = []\n",
    "for a in soup.find_all('p',{'class':'position'}):\n",
    "    ranking.append(a)\n",
    "\n",
    "rank = ranking\n",
    "rank = [row.text.strip().split(\"\\n\") for row in rank]\n",
    "#rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinar restaurantes\n",
    "restaurante = []\n",
    "for a in soup.find_all('h2'):\n",
    "    restaurante.append(a)\n",
    "rest = restaurante\n",
    "rest = [row.text.strip().split(\"\\n\") for row in rest]\n",
    "\n",
    "del rest[0]\n",
    "#rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the city\n",
    "cities = []\n",
    "for a in soup.find_all('h3'):\n",
    "    cities.append(a)\n",
    "city = cities\n",
    "city = [row.text.strip().split(\"\\n\") for row in city]\n",
    "#city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Ranking', 'Restaurant','City']\n",
    "dfR, dfRe, dfC = pd.DataFrame(rank), pd.DataFrame(rest), pd.DataFrame(city)\n",
    "Frame = pd.concat([dfR,dfRe,dfC], axis=1)\n",
    "Frame.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No.1</td>\n",
       "      <td>Mirazur</td>\n",
       "      <td>Menton, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No.2</td>\n",
       "      <td>Noma</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No.3</td>\n",
       "      <td>Asador Etxebarri</td>\n",
       "      <td>Axpe, Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No.4</td>\n",
       "      <td>Gaggan</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No.5</td>\n",
       "      <td>Geranium</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>No.116</td>\n",
       "      <td>St. Hubertus</td>\n",
       "      <td>San Cassiano, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>No.117</td>\n",
       "      <td>Epicure</td>\n",
       "      <td>Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>No.118</td>\n",
       "      <td>Ernst</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>No.119</td>\n",
       "      <td>Atomix</td>\n",
       "      <td>New York, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>No.120</td>\n",
       "      <td>Sugalabo</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking        Restaurant                 City\n",
       "0      No.1           Mirazur       Menton, France\n",
       "1      No.2              Noma  Copenhagen, Denmark\n",
       "2      No.3  Asador Etxebarri          Axpe, Spain\n",
       "3      No.4            Gaggan    Bangkok, Thailand\n",
       "4      No.5          Geranium  Copenhagen, Denmark\n",
       "..      ...               ...                  ...\n",
       "115  No.116      St. Hubertus  San Cassiano, Italy\n",
       "116  No.117           Epicure        Paris, France\n",
       "117  No.118             Ernst      Berlin, Germany\n",
       "118  No.119            Atomix        New York, USA\n",
       "119  No.120          Sugalabo         Tokyo, Japan\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame.to_csv('Frame.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTA API CALL NO SIRVIÓ PARA LO QUE BUSCABA\n",
    "\n",
    "#apiurl_cities = 'https://developers.zomato.com/api/v2.1/cities?q=france'\n",
    "#key_api = '51078b90a6b2e0fba70f111bcd6efd8f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apiresponse1 = requests.get(apiurl_cities, headers={'user-key':'51078b90a6b2e0fba70f111bcd6efd8f'})\n",
    "#results1 = apiresponse1.json()\n",
    "#results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlwiki = 'https://en.wikipedia.org/wiki/The_World%27s_50_Best_Restaurants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "      <th>3rd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>Gordon Ramsay</td>\n",
       "      <td>The French Laundry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>The French Laundry</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>Le Louis XV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>The French Laundry</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>elBulli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The French Laundry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>Pierre Gagnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>Pierre Gagnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>Pierre Gagnaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The Fat Duck</td>\n",
       "      <td>Noma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>Noma</td>\n",
       "      <td>elBulli</td>\n",
       "      <td>The Fat Duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011</td>\n",
       "      <td>Noma</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Mugaritz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012</td>\n",
       "      <td>Noma</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Mugaritz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Noma</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014</td>\n",
       "      <td>Noma</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "      <td>Noma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Eleven Madison Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>Eleven Madison Park</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>Osteria Francescana</td>\n",
       "      <td>El Celler de Can Roca</td>\n",
       "      <td>Mirazur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>Mirazur</td>\n",
       "      <td>Noma</td>\n",
       "      <td>Asador Etxebarri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year                     1st                     2nd  \\\n",
       "0   2002                 elBulli           Gordon Ramsay   \n",
       "1   2003      The French Laundry                 elBulli   \n",
       "2   2004      The French Laundry            The Fat Duck   \n",
       "3   2005            The Fat Duck                 elBulli   \n",
       "4   2006                 elBulli            The Fat Duck   \n",
       "5   2007                 elBulli            The Fat Duck   \n",
       "6   2008                 elBulli            The Fat Duck   \n",
       "7   2009                 elBulli            The Fat Duck   \n",
       "8   2010                    Noma                 elBulli   \n",
       "9   2011                    Noma   El Celler de Can Roca   \n",
       "10  2012                    Noma   El Celler de Can Roca   \n",
       "11  2013   El Celler de Can Roca                    Noma   \n",
       "12  2014                    Noma   El Celler de Can Roca   \n",
       "13  2015   El Celler de Can Roca     Osteria Francescana   \n",
       "14  2016     Osteria Francescana   El Celler de Can Roca   \n",
       "15  2017     Eleven Madison Park     Osteria Francescana   \n",
       "16  2018     Osteria Francescana   El Celler de Can Roca   \n",
       "17  2019                 Mirazur                    Noma   \n",
       "\n",
       "                       3rd  \n",
       "0       The French Laundry  \n",
       "1              Le Louis XV  \n",
       "2                  elBulli  \n",
       "3       The French Laundry  \n",
       "4          Pierre Gagnaire  \n",
       "5          Pierre Gagnaire  \n",
       "6          Pierre Gagnaire  \n",
       "7                     Noma  \n",
       "8             The Fat Duck  \n",
       "9                 Mugaritz  \n",
       "10                Mugaritz  \n",
       "11     Osteria Francescana  \n",
       "12     Osteria Francescana  \n",
       "13                    Noma  \n",
       "14     Eleven Madison Park  \n",
       "15   El Celler de Can Roca  \n",
       "16                 Mirazur  \n",
       "17        Asador Etxebarri  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Busca el historial de ganadores\n",
    "\n",
    "responsewiki = requests.get(urlwiki).content\n",
    "soupw = BeautifulSoup(responsewiki, 'lxml')\n",
    "\n",
    "wikitable= soupw.find_all('table',{'class':'wikitable'})[0]\n",
    "wrows= wikitable.find_all('tr')\n",
    "wrows=[row.text.strip().split('\\n')for row in wrows]\n",
    "\n",
    "del wrows [0]\n",
    "del wrows [0]\n",
    "wcols = ['Year','null','1st','null','2nd','null','3rd']\n",
    "wdf=pd.DataFrame(wrows, columns=wcols)\n",
    "wdf=wdf.drop('null', axis=1)\n",
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la lista de los restaurantes del mundo con m3 o más estrellas Michelin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://en.wikipedia.org/wiki/List_of_Michelin_3-star_restaurants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "response5 = requests.get(url5).content\n",
    "soup5 = BeautifulSoup(response5, 'lxml')\n",
    "\n",
    "table5= soup5.find_all('table',{'class':'wikitable'})[1]\n",
    "rows5= table5.find_all('tr')\n",
    "rows5=[row.text.strip().split('\\n')for row in rows5]\n",
    "del rows5 [0]\n",
    "df5 = pd.DataFrame(rows5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "response6 = requests.get(url5).content\n",
    "soup6 = BeautifulSoup(response5, 'lxml')\n",
    "\n",
    "table6= soup6.find_all('table',{'class':'wikitable'})[2]\n",
    "rows6= table6.find_all('tr')\n",
    "rows6=[row.text.strip().split('\\n')for row in rows6]\n",
    "del rows6[0]\n",
    "df6 = pd.DataFrame(rows6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "response7 = requests.get(url5).content\n",
    "soup7 = BeautifulSoup(response7, 'lxml')\n",
    "\n",
    "table7= soup7.find_all('table',{'class':'wikitable'})[3]\n",
    "rows7= table7.find_all('tr')\n",
    "rows7=[row.text.strip().split('\\n')for row in rows7]\n",
    "del rows7[0]\n",
    "df7 = pd.DataFrame(rows7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "response8 = requests.get(url5).content\n",
    "soup8 = BeautifulSoup(response8, 'lxml')\n",
    "\n",
    "table8= soup8.find_all('table',{'class':'wikitable'})[4]\n",
    "rows8= table8.find_all('tr')\n",
    "rows8=[row.text.strip().split('\\n')for row in rows8]\n",
    "del rows8[0]\n",
    "df8 = pd.DataFrame(rows8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "response9 = requests.get(url5).content\n",
    "soup9 = BeautifulSoup(response9, 'lxml')\n",
    "\n",
    "table9= soup9.find_all('table',{'class':'wikitable'})[5]\n",
    "rows9= table9.find_all('tr')\n",
    "rows9=[row.text.strip().split('\\n')for row in rows9]\n",
    "del rows9 [0]\n",
    "df9 = pd.DataFrame(rows9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "response11 = requests.get(url5).content\n",
    "soup11 = BeautifulSoup(response11, 'lxml')\n",
    "\n",
    "table11= soup11.find_all('table',{'class':'wikitable'})[6]\n",
    "rows11= table11.find_all('tr')\n",
    "rows11=[row.text.strip().split('\\n')for row in rows11]\n",
    "del rows11 [0]\n",
    "df11 = pd.DataFrame(rows11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "response12 = requests.get(url5).content\n",
    "soup12 = BeautifulSoup(response12, 'lxml')\n",
    "\n",
    "table12= soup12.find_all('table',{'class':'wikitable'})[7]\n",
    "rows12= table12.find_all('tr')\n",
    "rows12=[row.text.strip().split('\\n')for row in rows12]\n",
    "del rows12 [0]\n",
    "df12 = pd.DataFrame(rows12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "response13 = requests.get(url5).content\n",
    "soup13 = BeautifulSoup(response13, 'lxml')\n",
    "\n",
    "table13= soup13.find_all('table',{'class':'wikitable'})[8]\n",
    "rows13= table13.find_all('tr')\n",
    "rows13=[row.text.strip().split('\\n')for row in rows13]\n",
    "del rows13 [0]\n",
    "df13 = pd.DataFrame(rows13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "response14 = requests.get(url5).content\n",
    "soup14 = BeautifulSoup(response14, 'lxml')\n",
    "\n",
    "table14= soup14.find_all('table',{'class':'wikitable'})[9]\n",
    "rows14= table14.find_all('tr')\n",
    "rows14=[row.text.strip().split('\\n')for row in rows14]\n",
    "del rows14 [0]\n",
    "df14 = pd.DataFrame(rows14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "response15 = requests.get(url5).content\n",
    "soup15 = BeautifulSoup(response15, 'lxml')\n",
    "\n",
    "table15= soup15.find_all('table',{'class':'wikitable'})[10]\n",
    "rows15= table15.find_all('tr')\n",
    "rows15=[row.text.strip().split('\\n')for row in rows15]\n",
    "del rows15 [0]\n",
    "df15 = pd.DataFrame(rows15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "response16 = requests.get(url5).content\n",
    "soup16 = BeautifulSoup(response16, 'lxml')\n",
    "\n",
    "table16= soup16.find_all('table',{'class':'wikitable'})[11]\n",
    "rows16= table16.find_all('tr')\n",
    "rows16=[row.text.strip().split('\\n')for row in rows16]\n",
    "del rows16 [0]\n",
    "df16 = pd.DataFrame(rows16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "response17 = requests.get(url5).content\n",
    "soup17 = BeautifulSoup(response17, 'lxml')\n",
    "\n",
    "table17= soup17.find_all('table',{'class':'wikitable'})[12]\n",
    "rows17= table17.find_all('tr')\n",
    "rows17=[row.text.strip().split('\\n')for row in rows17]\n",
    "del rows17 [0]\n",
    "df17 = pd.DataFrame(rows17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "response18 = requests.get(url5).content\n",
    "soup18 = BeautifulSoup(response18, 'lxml')\n",
    "\n",
    "table18= soup18.find_all('table',{'class':'wikitable'})[13]\n",
    "rows18= table18.find_all('tr')\n",
    "rows18=[row.text.strip().split('\\n')for row in rows18]\n",
    "del rows18 [0]\n",
    "df18 = pd.DataFrame(rows18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "response19 = requests.get(url5).content\n",
    "soup19 = BeautifulSoup(response19, 'lxml')\n",
    "\n",
    "table19= soup19.find_all('table',{'class':'wikitable'})[14]\n",
    "rows19= table19.find_all('tr')\n",
    "rows19=[row.text.strip().split('\\n')for row in rows19]\n",
    "del rows19 [0]\n",
    "df19 = pd.DataFrame(rows19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "response20 = requests.get(url5).content\n",
    "soup20 = BeautifulSoup(response20, 'lxml')\n",
    "\n",
    "table20= soup20.find_all('table',{'class':'wikitable'})[15]\n",
    "rows20= table20.find_all('tr')\n",
    "rows20=[row.text.strip().split('\\n')for row in rows20]\n",
    "del rows20 [0]\n",
    "df20 = pd.DataFrame(rows20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basel</td>\n",
       "      <td>Cheval Blanc</td>\n",
       "      <td>Peter Knogl</td>\n",
       "      <td>2016[81]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crissier</td>\n",
       "      <td>Restaurant de l'Hôtel de Ville</td>\n",
       "      <td>Franck Giovannini</td>\n",
       "      <td>1992[82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fürstenau</td>\n",
       "      <td>Schloss Schauenstein</td>\n",
       "      <td>Andreas Caminada</td>\n",
       "      <td>2011[83]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                               1                  2         3\n",
       "0      Basel                    Cheval Blanc        Peter Knogl  2016[81]\n",
       "1   Crissier  Restaurant de l'Hôtel de Ville  Franck Giovannini  1992[82]\n",
       "2  Fürstenau            Schloss Schauenstein   Andreas Caminada  2011[83]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response21 = requests.get(url5).content\n",
    "soup21 = BeautifulSoup(response21, 'lxml')\n",
    "\n",
    "table21= soup21.find_all('table',{'class':'wikitable'})[16]\n",
    "rows21= table21.find_all('tr')\n",
    "rows21=[row.text.strip().split('\\n')for row in rows21]\n",
    "del rows21 [0]\n",
    "df21 = pd.DataFrame(rows21)\n",
    "df21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "response22 = requests.get(url5).content\n",
    "soup22 = BeautifulSoup(response22, 'lxml')\n",
    "\n",
    "table22= soup22.find_all('table',{'class':'wikitable'})[17]\n",
    "rows22= table22.find_all('tr')\n",
    "rows22=[row.text.strip().split('\\n')for row in rows22]\n",
    "del rows22 [0]\n",
    "df22 = pd.DataFrame(rows22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "response23 = requests.get(url5).content\n",
    "soup23 = BeautifulSoup(response23, 'lxml')\n",
    "\n",
    "table23= soup23.find_all('table',{'class':'wikitable'})[18]\n",
    "rows23= table23.find_all('tr')\n",
    "rows23=[row.text.strip().split('\\n')for row in rows23]\n",
    "del rows23 [0]\n",
    "df23 = pd.DataFrame(rows23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Alinea</td>\n",
       "      <td>Grant Achatz and Simon Davies[91]</td>\n",
       "      <td>2011[92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healdsburg</td>\n",
       "      <td>SingleThread</td>\n",
       "      <td>Kyle Connaughton</td>\n",
       "      <td>2019[93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>Manresa</td>\n",
       "      <td>David Kinch[94][95] and Nicholas Romero[96]</td>\n",
       "      <td>2016[97]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Le Bernardin</td>\n",
       "      <td>Éric Ripert,[98] Chris Muller,[99] and Eric Ge...</td>\n",
       "      <td>2006[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Per Se</td>\n",
       "      <td>Thomas Keller[102] and Corey Chow[103][104]</td>\n",
       "      <td>2006[101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Masa</td>\n",
       "      <td>Masa Takayama</td>\n",
       "      <td>2009[105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Eleven Madison Park</td>\n",
       "      <td>Daniel Humm and Brian Lockwood</td>\n",
       "      <td>2012[106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Chef's Table at Brooklyn Fare</td>\n",
       "      <td>César Ramírez</td>\n",
       "      <td>2012[106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Atelier Crenn</td>\n",
       "      <td>Dominique Crenn</td>\n",
       "      <td>2019[93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Benu</td>\n",
       "      <td>Corey Lee and Brandon Rodgers</td>\n",
       "      <td>2015[107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Quince</td>\n",
       "      <td>Michael Tusk and Neil Stetz</td>\n",
       "      <td>2017[108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>St. Helena</td>\n",
       "      <td>The Restaurant at Meadowood</td>\n",
       "      <td>Christopher Kostow and John Hong</td>\n",
       "      <td>2011[109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington</td>\n",
       "      <td>The Inn at Little Washington</td>\n",
       "      <td>Patrick O’Connell</td>\n",
       "      <td>2019[110][111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yountville</td>\n",
       "      <td>The French Laundry</td>\n",
       "      <td>Thomas Keller and David Breeden[112][113]</td>\n",
       "      <td>2007[114]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                              1  \\\n",
       "0         Chicago                         Alinea   \n",
       "1      Healdsburg                   SingleThread   \n",
       "2       Los Gatos                        Manresa   \n",
       "3   New York City                   Le Bernardin   \n",
       "4   New York City                         Per Se   \n",
       "5   New York City                           Masa   \n",
       "6   New York City            Eleven Madison Park   \n",
       "7   New York City  Chef's Table at Brooklyn Fare   \n",
       "8   San Francisco                  Atelier Crenn   \n",
       "9   San Francisco                           Benu   \n",
       "10  San Francisco                         Quince   \n",
       "11     St. Helena    The Restaurant at Meadowood   \n",
       "12     Washington   The Inn at Little Washington   \n",
       "13     Yountville             The French Laundry   \n",
       "\n",
       "                                                    2               3  \n",
       "0                   Grant Achatz and Simon Davies[91]        2011[92]  \n",
       "1                                    Kyle Connaughton        2019[93]  \n",
       "2         David Kinch[94][95] and Nicholas Romero[96]        2016[97]  \n",
       "3   Éric Ripert,[98] Chris Muller,[99] and Eric Ge...       2006[101]  \n",
       "4         Thomas Keller[102] and Corey Chow[103][104]       2006[101]  \n",
       "5                                       Masa Takayama       2009[105]  \n",
       "6                      Daniel Humm and Brian Lockwood       2012[106]  \n",
       "7                                       César Ramírez       2012[106]  \n",
       "8                                     Dominique Crenn        2019[93]  \n",
       "9                       Corey Lee and Brandon Rodgers       2015[107]  \n",
       "10                        Michael Tusk and Neil Stetz       2017[108]  \n",
       "11                   Christopher Kostow and John Hong       2011[109]  \n",
       "12                                  Patrick O’Connell  2019[110][111]  \n",
       "13          Thomas Keller and David Breeden[112][113]       2007[114]  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response24 = requests.get(url5).content\n",
    "soup24 = BeautifulSoup(response24, 'lxml')\n",
    "\n",
    "table24= soup24.find_all('table',{'class':'wikitable'})[19]\n",
    "rows24= table24.find_all('tr')\n",
    "rows24=[row.text.strip().split('\\n')for row in rows24]\n",
    "del rows24 [0]\n",
    "df24 = pd.DataFrame(rows24)\n",
    "df24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO me salió concatenar los data frames en uno solo, intenté .concat, .append con mil sintaxis distintas y no jala :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
